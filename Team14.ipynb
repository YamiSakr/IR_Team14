{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fCxiCgMFhwq",
        "outputId": "8b57eb4a-1f23-4ed0-b24c-d02cf8d1a78d",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-terrier in /usr/local/lib/python3.10/dist-packages (0.10.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from python-terrier) (1.25.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from python-terrier) (2.0.3)\n",
            "Requirement already satisfied: wget in /usr/local/lib/python3.10/dist-packages (from python-terrier) (3.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from python-terrier) (4.66.4)\n",
            "Requirement already satisfied: pyjnius>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from python-terrier) (1.6.1)\n",
            "Requirement already satisfied: matchpy in /usr/local/lib/python3.10/dist-packages (from python-terrier) (0.5.5)\n",
            "Requirement already satisfied: deprecated in /usr/local/lib/python3.10/dist-packages (from python-terrier) (1.2.14)\n",
            "Requirement already satisfied: chest in /usr/local/lib/python3.10/dist-packages (from python-terrier) (0.2.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from python-terrier) (1.11.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from python-terrier) (2.31.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from python-terrier) (1.4.2)\n",
            "Requirement already satisfied: nptyping==1.4.4 in /usr/local/lib/python3.10/dist-packages (from python-terrier) (1.4.4)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from python-terrier) (10.1.0)\n",
            "Requirement already satisfied: ir-datasets>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from python-terrier) (0.5.7)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from python-terrier) (3.1.4)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.10/dist-packages (from python-terrier) (0.14.2)\n",
            "Requirement already satisfied: ir-measures>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from python-terrier) (0.3.3)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from python-terrier) (0.3.8)\n",
            "Requirement already satisfied: pytrec-eval-terrier>=0.5.3 in /usr/local/lib/python3.10/dist-packages (from python-terrier) (0.5.6)\n",
            "Requirement already satisfied: typish>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from nptyping==1.4.4->python-terrier) (1.9.3)\n",
            "Requirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from ir-datasets>=0.3.2->python-terrier) (4.12.3)\n",
            "Requirement already satisfied: inscriptis>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from ir-datasets>=0.3.2->python-terrier) (2.5.0)\n",
            "Requirement already satisfied: lxml>=4.5.2 in /usr/local/lib/python3.10/dist-packages (from ir-datasets>=0.3.2->python-terrier) (4.9.4)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ir-datasets>=0.3.2->python-terrier) (6.0.1)\n",
            "Requirement already satisfied: trec-car-tools>=2.5.4 in /usr/local/lib/python3.10/dist-packages (from ir-datasets>=0.3.2->python-terrier) (2.6)\n",
            "Requirement already satisfied: lz4>=3.1.10 in /usr/local/lib/python3.10/dist-packages (from ir-datasets>=0.3.2->python-terrier) (4.3.3)\n",
            "Requirement already satisfied: warc3-wet>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from ir-datasets>=0.3.2->python-terrier) (0.2.3)\n",
            "Requirement already satisfied: warc3-wet-clueweb09>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from ir-datasets>=0.3.2->python-terrier) (0.2.5)\n",
            "Requirement already satisfied: zlib-state>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from ir-datasets>=0.3.2->python-terrier) (0.1.6)\n",
            "Requirement already satisfied: ijson>=3.1.3 in /usr/local/lib/python3.10/dist-packages (from ir-datasets>=0.3.2->python-terrier) (3.2.3)\n",
            "Requirement already satisfied: unlzw3>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from ir-datasets>=0.3.2->python-terrier) (0.2.2)\n",
            "Requirement already satisfied: cwl-eval>=1.0.10 in /usr/local/lib/python3.10/dist-packages (from ir-measures>=0.3.1->python-terrier) (1.0.12)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->python-terrier) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->python-terrier) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->python-terrier) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->python-terrier) (2024.2.2)\n",
            "Requirement already satisfied: heapdict in /usr/local/lib/python3.10/dist-packages (from chest->python-terrier) (1.0.1)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated->python-terrier) (1.14.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->python-terrier) (2.1.5)\n",
            "Requirement already satisfied: multiset<3.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from matchpy->python-terrier) (2.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->python-terrier) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->python-terrier) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->python-terrier) (2024.1)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.10/dist-packages (from statsmodels->python-terrier) (0.5.6)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels->python-terrier) (24.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.4.1->ir-datasets>=0.3.2->python-terrier) (2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.6->statsmodels->python-terrier) (1.16.0)\n",
            "Requirement already satisfied: cbor>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from trec-car-tools>=2.5.4->ir-datasets>=0.3.2->python-terrier) (1.0.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Setting Up the Environment\n",
        "!pip install python-terrier\n",
        "!pip install nltk\n",
        "!pip install beautifulsoup4\n",
        "!pip install requests\n",
        "!pip install pandas"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Importing Libraries and Initializing PyTerrier\n",
        "import pyterrier as pt\n",
        "if not pt.started():\n",
        "    pt.init()\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "import pandas as pd\n",
        "import requests\n",
        "from bs4 import BeautifulSoup"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DelVnWoKFjjW",
        "outputId": "2db40264-30a4-4e0d-a15e-97a07c56a0bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Data Collection and Web Crawling\n",
        "# Sample document collection for academic papers from arXiv\n",
        "urls = [\n",
        "    \"https://arxiv.org/abs/2201.00001\",\n",
        "    \"https://arxiv.org/abs/2201.00002\",\n",
        "    \"https://arxiv.org/abs/2201.00003\",\n",
        "]\n",
        "\n",
        "def crawl_web_page(url):\n",
        "    response = requests.get(url)\n",
        "    if response.status_code == 200:\n",
        "        page_content = response.text\n",
        "        soup = BeautifulSoup(page_content, 'html.parser')\n",
        "        # Extract relevant sections (title, abstract, and main text)\n",
        "        title = soup.find('h1', {'class': 'title'}).get_text(strip=True)\n",
        "        authors = soup.find('div', {'class': 'authors'}).get_text(strip=True)\n",
        "        abstract = soup.find('blockquote', {'class': 'abstract'}).get_text(strip=True)\n",
        "        keywords_tag = soup.find('meta', {'name': 'keywords'})\n",
        "        keywords = keywords_tag['content'] if keywords_tag else ''\n",
        "        text = title + \" \" + authors + \" \" + abstract + \" \" + keywords\n",
        "        return text\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "crawled_docs = []\n",
        "for i, url in enumerate(urls):\n",
        "    text = crawl_web_page(url)\n",
        "    if text:\n",
        "        crawled_docs.append({\"docno\": f\"crawled_{i}\", \"text\": text})\n",
        "\n",
        "# Convert crawled documents to DataFrame\n",
        "docs_df = pd.DataFrame(crawled_docs)"
      ],
      "metadata": {
        "id": "GK6LzDJMFlLc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Preprocessing the Text\n",
        "def preprocess_text(text):\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    stemmer = PorterStemmer()\n",
        "    words = word_tokenize(text.lower())\n",
        "    words = [stemmer.stem(word) for word in words if word not in stop_words]\n",
        "    return ' '.join(words)\n",
        "\n",
        "docs_df['processed_text'] = docs_df['text'].apply(preprocess_text)\n",
        "print(\"Combined and Preprocessed Documents:\")\n",
        "print(docs_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5-oauQOFm9x",
        "outputId": "7c23fda6-e84c-42d0-a010-c4117c8a4482"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined and Preprocessed Documents:\n",
            "       docno                                               text  \\\n",
            "0  crawled_0  Title:Modeling Advection on Directed Graphs us...   \n",
            "1  crawled_1  Title:Time-Dependent Duhamel Renormalization m...   \n",
            "2  crawled_2  Title:Simulating local fields in carbon nanotu...   \n",
            "\n",
            "                                      processed_text  \n",
            "0  titl : model advect direct graph use matérn ga...  \n",
            "1  titl : time-depend duhamel renorm method multi...  \n",
            "2  titl : simul local field carbon nanotub reinfo...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Indexing the Documents\n",
        "indexer = pt.DFIndexer(\"./index\", overwrite=True)\n",
        "index_ref = indexer.index(docs_df[\"processed_text\"], docs_df[\"docno\"])\n",
        "index = pt.IndexFactory.of(index_ref)\n",
        "print(\"Index collection statistics:\")\n",
        "print(index.getCollectionStatistics().toString())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "McKxrMinFn9N",
        "outputId": "cb24781c-c4d9-4f5d-95c0-a295ca4b9d70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index collection statistics:\n",
            "Number of documents: 3\n",
            "Number of terms: 181\n",
            "Number of postings: 209\n",
            "Number of fields: 0\n",
            "Number of tokens: 306\n",
            "Field names: []\n",
            "Positions:   false\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Implementing the Retrieval Model\n",
        "bm25 = pt.BatchRetrieve(index, wmodel=\"BM25\")"
      ],
      "metadata": {
        "id": "Xm-8YaWfFpIV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Search Functionality\n",
        "def search(query):\n",
        "    query = preprocess_text(query)\n",
        "    results = bm25.search(query)\n",
        "    return results"
      ],
      "metadata": {
        "id": "OF8h1jIqFqKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 8: Evaluating the Retrieval System\n",
        "test_queries = [\n",
        "    {\"query\": \"deep learning in medical imaging\", \"relevant_docs\": [\"crawled_0\"]},\n",
        "    {\"query\": \"quantum computing algorithms\", \"relevant_docs\": [\"crawled_1\"]},\n",
        "    {\"query\": \"graph theory\", \"relevant_docs\": [\"crawled_0\"]},\n",
        "    {\"query\": \"carbon nanotubes simulation\", \"relevant_docs\": [\"crawled_2\"]},\n",
        "]\n",
        "\n",
        "def evaluate(test_queries):\n",
        "    precision_scores = []\n",
        "    recall_scores = []\n",
        "    f_measure_scores = []\n",
        "\n",
        "    for test_query in test_queries:\n",
        "        results = search(test_query[\"query\"])\n",
        "        retrieved_docs = results['docno'].tolist()\n",
        "        relevant_docs = test_query[\"relevant_docs\"]\n",
        "\n",
        "        true_positives = len(set(retrieved_docs) & set(relevant_docs))\n",
        "        precision = true_positives / len(retrieved_docs) if retrieved_docs else 0\n",
        "        recall = true_positives / len(relevant_docs) if relevant_docs else 0\n",
        "        f_measure = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "        precision_scores.append(precision)\n",
        "        recall_scores.append(recall)\n",
        "        f_measure_scores.append(f_measure)\n",
        "\n",
        "    return {\n",
        "        \"precision\": sum(precision_scores) / len(precision_scores),\n",
        "        \"recall\": sum(recall_scores) / len(recall_scores),\n",
        "        \"f_measure\": sum(f_measure_scores) / len(f_measure_scores),\n",
        "    }\n",
        "\n",
        "evaluation_results = evaluate(test_queries)\n",
        "print(\"Evaluation results:\")\n",
        "print(evaluation_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BUaWuI7BFrOD",
        "outputId": "3975393e-aa23-4be9-9425-313513abee5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation results:\n",
            "{'precision': 0.75, 'recall': 0.75, 'f_measure': 0.75}\n"
          ]
        }
      ]
    }
  ]
}